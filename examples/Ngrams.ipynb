{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For development, use local paths.\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load local\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nonconsumptive as nc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams\n",
    "\n",
    "N-grams can consist of any number of tokens. Distributing ngrams of any length potentially invites reconstruction, because all ngrams overlap with each other.\n",
    "\n",
    "There are a couple strategies for avoiding this.\n",
    "\n",
    "1. Distribute n-grams that are *broken* on certain chracaters. For instance, if you break all 7-grams at the period marker, the worst case scenario becomes that someone can reconstruct each indvidual sentence in a work but not the order of the sentences.\n",
    "\n",
    "2. Distribute only a subset of bigrams. Stratg is the subject of forthcoming work with Peter Organisciak that will hopefully be incorporated into this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "folder = Path(tempfile.gettempdir() + \"/gutenberg\")\n",
    "if folder.exists():\n",
    "    shutil.rmtree(folder)\n",
    "folder.mkdir()\n",
    "\n",
    "gutenberg = nc.Corpus(\n",
    "    texts = \"../sample_inputs/gutenberg/texts\",\n",
    "    metadata = \"../sample_inputs/gutenberg/metadata.ndjson\",\n",
    "    dir = folder,\n",
    "    compression = \"gz\",\n",
    "    cache_set = {\"tokenization\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nonconsumptive.corpus import Ngrams, Bigrams, Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tokenization\n",
      "Building cache\n"
     ]
    }
   ],
   "source": [
    "g = Trigrams(gutenberg)\n",
    "all = []\n",
    "for trigrams in g:\n",
    "    all.append(trigrams)\n",
    "    \n",
    "import pyarrow as pa\n",
    "total_trigrams = pa.Table.from_batches(all).to_pandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Field<count: uint32>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.arrow_schema.field('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token1</th>\n",
       "      <th>token2</th>\n",
       "      <th>token3</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1349117</th>\n",
       "      <td>I</td>\n",
       "      <td>don</td>\n",
       "      <td>’</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299070</th>\n",
       "      <td>Madame</td>\n",
       "      <td>de</td>\n",
       "      <td>Bellegarde</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406194</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>.</td>\n",
       "      <td>Hudson</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3551344</th>\n",
       "      <td>Mr</td>\n",
       "      <td>.</td>\n",
       "      <td>Brand</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519392</th>\n",
       "      <td>Mr</td>\n",
       "      <td>.</td>\n",
       "      <td>Weston</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081643</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>.</td>\n",
       "      <td>Norris</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026438</th>\n",
       "      <td>I</td>\n",
       "      <td>'</td>\n",
       "      <td>m</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535490</th>\n",
       "      <td>Mr</td>\n",
       "      <td>.</td>\n",
       "      <td>Wentworth</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841000</th>\n",
       "      <td>D</td>\n",
       "      <td>'</td>\n",
       "      <td>Arnot</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110499</th>\n",
       "      <td>Mr</td>\n",
       "      <td>.</td>\n",
       "      <td>Crawford</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877661</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>.</td>\n",
       "      <td>Vivian</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433822</th>\n",
       "      <td>Mr</td>\n",
       "      <td>.</td>\n",
       "      <td>Elton</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307027</th>\n",
       "      <td>I</td>\n",
       "      <td>don</td>\n",
       "      <td>’</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756946</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>.</td>\n",
       "      <td>Jennings</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443250</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>.</td>\n",
       "      <td>Weston</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889346</th>\n",
       "      <td>Fu</td>\n",
       "      <td>-</td>\n",
       "      <td>Manchu</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296221</th>\n",
       "      <td>Newman</td>\n",
       "      <td>.</td>\n",
       "      <td>“</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224170</th>\n",
       "      <td>Madame</td>\n",
       "      <td>de</td>\n",
       "      <td>Cintré</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415474</th>\n",
       "      <td>Mr</td>\n",
       "      <td>.</td>\n",
       "      <td>Knightley</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136626</th>\n",
       "      <td>Mr</td>\n",
       "      <td>.</td>\n",
       "      <td>Fogg</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token1 token2      token3  count\n",
       "1349117       I    don           ’    153\n",
       "3299070  Madame     de  Bellegarde    162\n",
       "1406194     Mrs      .      Hudson    162\n",
       "3551344      Mr      .       Brand    164\n",
       "519392       Mr      .      Weston    167\n",
       "3081643     Mrs      .      Norris    174\n",
       "1026438       I      '           m    176\n",
       "3535490      Mr      .   Wentworth    184\n",
       "841000        D      '       Arnot    193\n",
       "3110499      Mr      .    Crawford    199\n",
       "1877661     Mrs      .      Vivian    226\n",
       "433822       Mr      .       Elton    229\n",
       "3307027       I    don           ’    233\n",
       "2756946     Mrs      .    Jennings    234\n",
       "443250      Mrs      .      Weston    256\n",
       "2889346      Fu      -      Manchu    269\n",
       "3296221  Newman      .           “    279\n",
       "3224170  Madame     de      Cintré    296\n",
       "415474       Mr      .   Knightley    299\n",
       "1136626      Mr      .        Fogg    356"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_trigrams.query(\"token1.str.match('[A-Z]')\").sort_values(\"count\", ascending = True).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed = total_trigrams.set_index([\"token1\", \"token2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Rachel , weeping for her first love , who in some monomaniac way whatever whales he could be got up ; the man for a spell ; a wondrous "
     ]
    }
   ],
   "source": [
    "chain = [\"the\", \"Rachel\"]\n",
    "print(\" \".join(chain), end = \" \")\n",
    "while len(chain) < 30:\n",
    "    filtered = indexed.loc[chain[-2]].loc[[chain[-1]]]\n",
    "    sampled = filtered.sample(n=1, weights=filtered.iloc[:,1], )\n",
    "    new_word = list(filtered['token3'])[0]\n",
    "    print(new_word, end = \" \")\n",
    "    chain.append(new_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token3</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>picnic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token3  count\n",
       "token2               \n",
       "a       picnic      1"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.sample(n=1, weights=filtered.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
